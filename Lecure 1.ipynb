{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 1: Introduction and Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture introduces the course and its syllabus as well as providing a brief overview of the various topics we'll cover and the utility of machine learning.\n",
    "\n",
    "We additionally will cover information about the various tools we will be using in this course. We will discuss the niche of each tool, how we will use it, and how to get it set up on your local machine.\n",
    "***\n",
    "Basic course information, schedules, assignments, and resources are located [here](https://canvas.uw.edu/courses/1192473)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine Learning: Human Problems Versus Computer Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Machine Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most problems can be split into two categories: things a computer would be good at and things a person would be good at. Traditionally, these two categories tend to have little overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problems well suited to computers tend to be those which are:\n",
    "* deterministic\n",
    "* repetitive\n",
    "* computationally intensive\n",
    "\n",
    "Typically, these problems would take a very long time for a person to do, but can be coded up quickly and simply. For example, consider computing the factorial for a moderately sized number. For a person, mentally calculating $18!$ would take quite a while, but a computer can do it near instantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The factorial of 18 is 6402373705728000\n",
      "Compute Time: 0.000569\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Python program to find the factorial of a number provided by the user.\n",
    "\n",
    "# change the value for a different result\n",
    "num = 18\n",
    "\n",
    "# uncomment to take input from the user\n",
    "#num = int(input(\"Enter a number: \"))\n",
    "now = time.clock()\n",
    "factorial = 1\n",
    "\n",
    "# check if the number is negative, positive or zero\n",
    "if num < 0:\n",
    "   print(\"Sorry, factorial does not exist for negative numbers\")\n",
    "elif num == 0:\n",
    "   print(\"The factorial of 0 is 1\")\n",
    "else:\n",
    "   for i in range(1,num + 1):\n",
    "       factorial = factorial*i\n",
    "   print(\"The factorial of\",num,\"is\",factorial)\n",
    "print(\"Compute Time: %f\" % (time.clock() - now))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half a millisecond is pretty good for such a big computation!\n",
    "***\n",
    "This type of problem appears very frequently and typically can be implemented in a fairly obvious way. It is important to recognize this kind of problem because they are NOT suitable for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Human Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to machine problems, human problems are tasks that we are actually quite good at! A few basic examples include understanding a spoken word, identifying a dog in a herd of sheep, or guessing which new movie your friend might like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ImageDet](https://kaggle2.blob.core.windows.net/competitions/kaggle/3333/media/INODex2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![SpeechDet](http://gluon.mxnet.io/_images/wake-word.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although these types of tasks seem simple, when we sit down and think about how to code up something that works well, it becomes very difficult. Consider a picture of cat. The a program, all we have is matrix of pixels, figuring out what those pixels represent would be quite difficult using conventional coding methods.\n",
    "\n",
    "These typse of problems are extremely well suited to machine learning, and will be the focus of much of this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Machine Learning Examples\n",
    "Some examples of machine learning tasks that we will cover in this course include"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Regression</center>\n",
    "![regression](https://media.licdn.com/mpr/mpr/AAEAAQAAAAAAAAfpAAAAJDI1YzM1MGQ4LTc4NDQtNDJiMS1iYmYwLTIyNzUwNmI4Njc0MA.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Classification</center>\n",
    "![deathcap](http://gluon.mxnet.io/_images/death_cap.jpg)\n",
    "<center>Death cap - do not eat!</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Detection</center>\n",
    "![detection](http://en.people.cn/NMediaFile/2017/0804/FOREIGN201708041620000597246818595.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Speech Recognition</center>\n",
    "<center>----D----e----e-----p------- L----ea------r------ni-----ng---</center>\n",
    "![recog](http://gluon.mxnet.io/_images/speech.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Captioning</center>\n",
    "![detection](https://idealog.co.nz/media/VERSIONS/images/google_950x700--upscale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along with many other tasks. You might notice that some of the examples above have very impactful applications. It would be good to try to think up some of your own machine learning applications since they might be applicable to your term project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tools and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. MXNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although it would be relatively simple to code up a small neural network, the very large networks used in modern machine learning quickly become untenable to hand code. This has led to the development of many machine learning framework. Some of the most popular frameworks you've likely heard about include Tensorflow, Caffe, and Torch. Each framework accels in certain areas, has weaknesses in others, and is supported by varying groups. In this course, we will be using MXNet.\n",
    "\n",
    "MXNet is a relatively new framework (developed in large part at UW!) that has been adopted by Amazon as its framework of choice. With it's 1.0 release, it has two key benefits that make it ideal for us: extremely clean syntax and the ability to deploy to any platform. For comparison, Tensorflow is great for deploying but has some of the worst syntax (and hence difficulty to learn) of any framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1. Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a few snippets of MXNet to get a feel for how it works and can be used. If you're ambitious, there's an excellent crash course (parts of which will mirror the content of this course) available [here](http://gluon.mxnet.io/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[  6.97250574e+15   4.55604170e-41  -1.18404297e+03   3.09196506e-41]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]\n",
      " [  0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00]]\n",
      "<NDArray 3x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# import MXNet and its array handling module\n",
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "# use a fixed seed so results are always the same\n",
    "mx.random.seed(1)\n",
    "# create an empty matrix with three rows and four columns\n",
    "x = nd.empty((3, 4))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that x is initialized to random values (because we used the empty function). If we want zero intialization, we can instead say..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "<NDArray 3x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "x = nd.zeros((3, 4))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NDArray objects have many useful properties and methods that can be inspected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T',\n",
       " '__add__',\n",
       " '__array_priority__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__del__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__idiv__',\n",
       " '__imod__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__isub__',\n",
       " '__itruediv__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__rpow__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '_at',\n",
       " '_fresh_grad',\n",
       " '_get_index_nd',\n",
       " '_get_nd_advanced_indexing',\n",
       " '_get_nd_basic_indexing',\n",
       " '_prepare_value_nd',\n",
       " '_set_nd_advanced_indexing',\n",
       " '_set_nd_basic_indexing',\n",
       " '_slice',\n",
       " '_sync_copyfrom',\n",
       " '_to_shared_mem',\n",
       " 'abs',\n",
       " 'arccos',\n",
       " 'arccosh',\n",
       " 'arcsin',\n",
       " 'arcsinh',\n",
       " 'arctan',\n",
       " 'arctanh',\n",
       " 'argmax',\n",
       " 'argmax_channel',\n",
       " 'argmin',\n",
       " 'argsort',\n",
       " 'as_in_context',\n",
       " 'asnumpy',\n",
       " 'asscalar',\n",
       " 'astype',\n",
       " 'attach_grad',\n",
       " 'backward',\n",
       " 'broadcast_axes',\n",
       " 'broadcast_to',\n",
       " 'cbrt',\n",
       " 'ceil',\n",
       " 'clip',\n",
       " 'context',\n",
       " 'copy',\n",
       " 'copyto',\n",
       " 'cos',\n",
       " 'cosh',\n",
       " 'degrees',\n",
       " 'detach',\n",
       " 'dtype',\n",
       " 'exp',\n",
       " 'expand_dims',\n",
       " 'expm1',\n",
       " 'fix',\n",
       " 'flatten',\n",
       " 'flip',\n",
       " 'floor',\n",
       " 'grad',\n",
       " 'handle',\n",
       " 'log',\n",
       " 'log10',\n",
       " 'log1p',\n",
       " 'log2',\n",
       " 'log_softmax',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'min',\n",
       " 'nanprod',\n",
       " 'nansum',\n",
       " 'ndim',\n",
       " 'norm',\n",
       " 'one_hot',\n",
       " 'ones_like',\n",
       " 'pad',\n",
       " 'pick',\n",
       " 'prod',\n",
       " 'radians',\n",
       " 'rcbrt',\n",
       " 'reciprocal',\n",
       " 'relu',\n",
       " 'repeat',\n",
       " 'reshape',\n",
       " 'reshape_like',\n",
       " 'rint',\n",
       " 'round',\n",
       " 'rsqrt',\n",
       " 'shape',\n",
       " 'sigmoid',\n",
       " 'sign',\n",
       " 'sin',\n",
       " 'sinh',\n",
       " 'size',\n",
       " 'slice',\n",
       " 'slice_axis',\n",
       " 'softmax',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'square',\n",
       " 'stype',\n",
       " 'sum',\n",
       " 'swapaxes',\n",
       " 'take',\n",
       " 'tan',\n",
       " 'tanh',\n",
       " 'tile',\n",
       " 'topk',\n",
       " 'tostype',\n",
       " 'transpose',\n",
       " 'trunc',\n",
       " 'wait_to_read',\n",
       " 'writable',\n",
       " 'zeros_like']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some that will come in handy quite often is looking at the shape of the matrix and the number of elements it contains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're familiar with Numpy (a very common python library that makes numerical operations faster) you're in luck! Nearly all Numpy operations have an equivalent NDarray function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.22575472 -2.61288834 -0.2142715  -5.2619853 ]\n",
       " [-0.11471695  0.62696832 -1.15302181 -2.22119904]\n",
       " [ 1.15921438 -0.45799193  2.08968568  1.62487364]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set x to be a matrix of normally distributed random numbers\n",
    "x = nd.random_normal(0, 1, (3,4))\n",
    "# add x to x\n",
    "x + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[  1.27412984e-02   1.70679641e+00   1.14780692e-02   6.92212248e+00]\n",
       " [  3.28999502e-03   9.82723162e-02   3.32364827e-01   1.23343134e+00]\n",
       " [  3.35944504e-01   5.24391532e-02   1.09169650e+00   6.60053611e-01]]\n",
       "<NDArray 3x4 @cpu(0)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute x squared\n",
    "x**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MXNet of course supports linear algebra operations, since nearly all machine learning is linear algebra at its core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 8.65313816  2.56772017 -1.8848604 ]\n",
       " [ 2.56772017  1.66735852 -1.60968721]\n",
       " [-1.8848604  -1.60968721  2.14013386]]\n",
       "<NDArray 3x3 @cpu(0)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute the matrix multiplication of x with its transpose\n",
    "nd.dot(x, x.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveniently, all MXNet matrices and tensors can be converted to numpy for use with other python modules (matplotlib for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.11287736, -1.30644417, -0.10713575, -2.63099265],\n",
       "       [-0.05735848,  0.31348416, -0.57651091, -1.11059952],\n",
       "       [ 0.57960719, -0.22899596,  1.04484284,  0.81243682]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.asnumpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're computer has a GPU, one of the main features of MXNet is that it makes using it super easy to speed up computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.11287736 -1.30644417 -0.10713575 -2.63099265]\n",
       " [-0.05735848  0.31348416 -0.57651091 -1.11059952]\n",
       " [ 0.57960719 -0.22899596  1.04484284  0.81243682]]\n",
       "<NDArray 3x4 @gpu(0)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transfer x on to the GPU\n",
    "x_gpu = x.copyto(mx.gpu(0))\n",
    "x_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.22575472 -2.61288834 -0.2142715  -5.2619853 ]\n",
       " [-0.11471695  0.62696832 -1.15302181 -2.22119904]\n",
       " [ 1.15921438 -0.45799193  2.08968568  1.62487364]]\n",
       "<NDArray 3x4 @gpu(0)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can now perform a gpu addition in the same way as we did on the cpu\n",
    "x_gpu + x_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice this actually took longer on the CPU. This is because the amount of work was quite small, so the added overhead of copying the data to the GPU actuallly took longer than the computation. When we start working with neural networks, having a GPU working will save you a lot of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although MXNet's math functionality is quite nice, the real attraction is the ability to simply define a neural network. Below we define a 3 layer neural network. Although we're not going to train or use it in this lecture, it's nice to see how simple it is to make a neural net!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "model_ctx = mx.cpu()\n",
    "class MLP(gluon.Block):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MLP, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.dense0 = gluon.nn.Dense(64, activation=\"relu\")\n",
    "            self.dense1 = gluon.nn.Dense(64, activation=\"relu\")\n",
    "            self.dense2 = gluon.nn.Dense(10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense0(x)\n",
    "        print(\"Hidden Representation 1: %s\" % x)\n",
    "        x = self.dense1(x)\n",
    "        print(\"Hidden Representation 2: %s\" % x)\n",
    "        x = self.dense2(x)\n",
    "        print(\"Network output: %s\" % x)\n",
    "        return x\n",
    "\n",
    "net = MLP()\n",
    "net.collect_params().initialize(mx.init.Normal(sigma=.01), ctx=model_ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (dense0): Dense(None -> 64, Activation(relu))\n",
       "  (dense1): Dense(None -> 64, Activation(relu))\n",
       "  (dense2): Dense(None -> 10, linear)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Docker](https://www.docker.com/sites/default/files/Package%20software.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker is a tool that allows containers with a specific environment to be independantly built and launched. This is really useful for complicated environments that need to run on a lot of systems! For us, this allows us to guarantee every student has the same environment ie same python version / juptyer environment / MXNet version regardless of what OS is being used.\n",
    "\n",
    "As you might imagine, in a large class having identical environments will cut back on a lot of bugs that otherwise would pop up!\n",
    "\n",
    "Docker containers can be thought of as miniature virtual machines that are highly portable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1. Independent Environments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first assignment will show how to set up and run a docker container. However, there are a few things to keep in mind.\n",
    "\n",
    "When a container is spawned, it is completely seperate from the rest of the computer. Everything you do and touch will disappear when the container exits. This can be both good and bad. It's good because if you accidentally mess something up, you can very easily just close the container and spawn a new one. It's bad because if you're not careful, some of your work might disappear!\n",
    "\n",
    "When you spawn a container, you can mount a directory using the -v option. This makes it so that changing files in that directory are shared between the container and the OS. Make sure that any work you want to save is in a mounted directory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jupyter Notebooks create an interactive coding environment. Snippets of code can be run in a cell, allowing easy debugging. Not only does this make writing code a much more pleasant experience, it also allows others to follow along with what you've done. Moreover, you can add good looking documentation and images easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lecture is a decent example of a Notebook! It contains some code segments and quite a bit of documentation, feel free to download it from the course website and poke around to see how things work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this course, the vast majority of content will be presented in Jupyter Notebooks. All lectures will be notebook style as will assignments. The first homework shows how to set up and start using your very own notebooks, I highly recommend you play around and get comfortable as you'll be using these quite a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
